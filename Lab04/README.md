# Lab 04

[Step 1](step1_streamlit-chatbot/README.md)


Creating a chatbot that connects to a hosted LLM is a great way to prototype production because it allows for rapid testing and iteration in a real-world scenario. By leveraging a hosted LLM, you can simulate how the model will interact with end-users, identify potential improvements, and observe how the chatbot handles various queries.

For effective LLM operations (LLMops), it's crucial to build in safety controls, such as content moderation, guardrails to prevent harmful outputs, and monitoring systems to track performance. These controls ensure that the chatbot operates responsibly and in line with compliance standards, while maintaining the flexibility to adapt the system for production-scale use.

Source: https://github.com/streamlit/chatbot-template

